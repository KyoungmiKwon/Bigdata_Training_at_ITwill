{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C05_JY_word2vec_softmax.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gwtJcsWeqrjKTfTFAeAMzVAuwf2jlVpW",
      "authorship_tag": "ABX9TyNWYzJOJK0LauX1ga/25AZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyoungmiKwon/Bigdata_Training_at_ITwill/blob/main/Team_Project/C05_JY_word2vec_softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKzHRro9fiMW"
      },
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUXjkxG2gaLD"
      },
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8223bSYQgdfm"
      },
      "source": [
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoFB_imVge6L"
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIarHf6hzMG"
      },
      "source": [
        "mecab=Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDY4kQMMh4mC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3KKpHTWQhpS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73s1GravQmaD"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX7nQJSgQq35"
      },
      "source": [
        "from gensim.models import word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcZn3RjPQ48B"
      },
      "source": [
        "\n",
        "from gensim.models import Doc2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSV86_LUQ7Rp"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPer8cCth9eq"
      },
      "source": [
        "url='https://github.com/KyoungmiKwon/Bigdata_Training_at_ITwill/raw/main/Team_Project/C01_KM_Data_Labeling_resized.xlsx'\n",
        "news=pd.read_excel(url,header=5,usecols=['Code','Date','Journal','Title','Text','URL','Sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rDqkOatiYMG"
      },
      "source": [
        "news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhPpDk8Iiiui"
      },
      "source": [
        "news=news.drop_duplicates(['Date'],keep='first')#첫번째 중복값 놔둠ews=news.drop_duplicates(['Date'],keep='first')#첫번째 중복값 놔둠"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnrEwFulj15x"
      },
      "source": [
        "news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqd8imBgj4GX"
      },
      "source": [
        "for i in range(len(news)):\n",
        "  news.iloc[i]['Text']=news.iloc[i]['Text'].split(sep='@')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kls0TBa4nklu"
      },
      "source": [
        "news.to_excel(\"articles.xlsx\")\n",
        "news = pd.read_excel('/content/articles.xlsx', header=0, usecols=['Code', 'Date', 'Journal', 'Title','Text', 'Sentiment'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOjfZ7jcnvy1"
      },
      "source": [
        "news\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_XXcZ1d-VWp"
      },
      "source": [
        "news[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETip1WrF-YXE"
      },
      "source": [
        "tag_classes=['NNP','NNG','VV+EC','XSV+EP']#추출할 품사 종류 \n",
        "stopwords=[np.nan,'삼성전자','삼성','인텔','데일리','기자','LG전자','LG','YG','JYP','뉴스','파이낸셜']\n",
        "Text=[]\n",
        "for main in news['Text']:\n",
        "  temp=[]\n",
        "  for word in mecab.pos(main): #mecab.post(단어, 품사 )형태의 word뽑아내서 하나씩 사용 \n",
        "    if word[1] in tag_classes:#word[1] 품사가 추출할 품사 종류에 들어 있으면 \n",
        "      if word[0] not in stopwords: #불용어에 들어 있지 않으면\n",
        "        temp.append(word[0]) #단어=>word추가 \n",
        "  Text.append(temp) #test셋 배열에 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JuicGjfObY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY51Rn4m_yoU"
      },
      "source": [
        "len(Text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EhKy2t-_0cx"
      },
      "source": [
        "Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhini-F5InUC"
      },
      "source": [
        "워드투벡터 인코딩 하기 위해서 \n",
        "단어, 품사 따로 저장 필요 \n",
        "왜 단어랑 태깅 정보를 따로 저장해야하지?\n",
        "\n",
        "sentences, pos_tags = [], [] \n",
        "for tagged_sentence in tagged_sentences: # 3,914개의 문장 샘플을 1개씩 불러온다.\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 품사 태깅 정보들은 tag_info에 저장한다.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    pos_tags.append(list(tag_info)) # 각 샘플에서 품사 태깅 정보만 저장한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS31Hll5Ovqa"
      },
      "source": [
        "\n",
        "#학습시 필요한 하이퍼 파라미터\n",
        "size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
        "window = 컨텍스트 윈도우 크기\n",
        "min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
        "workers = 학습을 위한 프로세스 수\n",
        "sg = 0은 CBOW, 1은 Skip-gram.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPHhN824IjDe"
      },
      "source": [
        "num_features=1500 #워드 벡터 특정 값 수 \n",
        "min_word_count=2\n",
        "num_workers=4\n",
        "context=5\n",
        "downsampling=1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DANg6MzPo85"
      },
      "source": [
        "\n",
        "model = word2vec.Word2Vec(Text,\n",
        "                        workers=num_workers,\n",
        "                        size=num_features,\n",
        "                        min_count=min_word_count,\n",
        "                        window=context,\n",
        "                        sample=downsampling) #epoch= 횟수 추가할수있음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-3esx2hQYyY"
      },
      "source": [
        "model_name=\"word2_model\"\n",
        "model.save(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jDxYboSReRH"
      },
      "source": [
        "def get_features(words, model, num_features):\n",
        "    # 출력 벡터 초기화\n",
        "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
        "    \n",
        "    num_words = 0\n",
        "    # 어휘 사전 준비\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    \n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words = 1\n",
        "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "            \n",
        "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Eul_8mUGPZ"
      },
      "source": [
        "def get_dataset(news, model, num_features):\n",
        "    dataset = list()\n",
        "    \n",
        "    for s in news:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "        \n",
        "    NewsFeatureVecs = np.stack(dataset)\n",
        "    return NewsFeatureVecs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T518x6ZtMDzc"
      },
      "source": [
        "test_data_vecs = get_dataset(Text, model, num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQZwcdYJMgm7"
      },
      "source": [
        "len(test_data_vecs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrQXzAlUMiDt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jcl8WIPZHf"
      },
      "source": [
        "X=test_data_vecs\n",
        "y=news['Sentiment'].values\n",
        "#y종속변수 x독립변수수\n",
        "#두 관계가 서로 영향을 미치나? \n",
        "#학생의 공부 시간에 따라서 다음과 같은 점수를 얻었다는 데이터\n",
        "#2시간 공부하면 25점\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,\n",
        "                                               test_size=0.2,\n",
        "                                               random_state=42)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#훈련셋 셰잎 3개로 맞춰줘야 소프트맥스 함수적용가능\n",
        "y_train = to_categorical(y_train,3)\n",
        "y_test = to_categorical(y_test,3)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터에 대해서 원-핫 인코딩\n",
        "print(y_train[:5])\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGZ5WZ1qAE36"
      },
      "source": [
        "print(y_train[:5])\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJfqaTvfbxS"
      },
      "source": [
        "print(\"라벨링종류\",news['Sentiment'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93gkVdAoTzb"
      },
      "source": [
        "print(\"벡터화된단어\",X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK8CnqgpNrAp"
      },
      "source": [
        "첫번째 인자 : 출력 뉴런의 수를 설정합니다.\n",
        "input_dim : 입력 뉴런의 수를 설정합니다.\n",
        "init : 가중치 초기화 방법 설정합니다.\n",
        "‘uniform’ : 균일 분포\n",
        "‘normal’ : 가우시안 분포\n",
        "activation : 활성화 함수 설정합니다.\n",
        "‘linear’ : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.\n",
        "‘relu’ : rectifier 함수, 은익층에 주로 쓰입니다.\n",
        "‘sigmoid’ : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다.\n",
        "‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WSxFBpUgszo"
      },
      "source": [
        "import seaborn as sns \n",
        "sns.set(style=\"ticks\",color_codes=True)\n",
        "g=sns.pairplot(news,hue=\"Sentiment\",palette=\"husl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvF1XrAn_Os"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "news['Sentiment'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Suwlin6Ayo6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(3,  activation='softmax'))\n",
        "sgd=optimizers.SGD(lr=0.01)\n",
        "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "#다중클래스 분류문제는 'categofical_crossentropy'\n",
        "# 옵티마이저는 경사하강법의 일종인 adam을 사용합니다.\n",
        "# 손실 함수(Loss function)는 크로스 엔트로피 함수를 사용합니다.\n",
        "history=model.fit(X_train,y_train, batch_size=1, epochs=200, validation_data=(X_test, y_test))\n",
        "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKskRzwmWCzR"
      },
      "source": [
        "accuracy:훈련데이터 정확도\n",
        "val_acc :테스트데이터 정확도 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmU_irVWOeo"
      },
      "source": [
        "에포크에 따른 정확도 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0EGpweHcGxc"
      },
      "source": [
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwgJ3YffRq0d"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1pzdhqAWaR7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}